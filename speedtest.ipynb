{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purposes:\n",
    "- speed test to find bottlenecks and further opportunities for optimization\n",
    "- apply the lessons from Mike Muller's 2019 PyCon talk: https://www.youtube.com/watch?v=EcGWDNlGTNg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from candidates import current_hamiltonian, current_simsignals, candidate_hamiltonian, candidate_simsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmrtools.qm import hamiltonian_dense, hamiltonian_sparse, nspinspec_dense, nspinspec_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_data import spin11, spin8, rioux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_h():\n",
    "    return current_hamiltonian(*spin11())\n",
    "\n",
    "def new_h():\n",
    "    return candidate_hamiltonian(*spin11())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old11_h = old_h()\n",
    "new11_h = new_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_s():\n",
    "    return current_simsignals(old11_h, 11)\n",
    "\n",
    "def new_s():\n",
    "    return candidate_simsignals(new11_h, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = spin11\n",
    "def old_h():\n",
    "    return hamiltonian_dense(*f())\n",
    "def new_h():\n",
    "    return hamiltonian_sparse(*f())\n",
    "\n",
    "def old_s():\n",
    "    return nspinspec_dense(*f())\n",
    "def new_s():\n",
    "    return nspinspec_sparse(*f())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(hamiltonian_dense(*rioux())))\n",
    "print(type(hamiltonian_sparse(*rioux())))\n",
    "print(type(hs2(*rioux())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use %timeit for a 1-liner, and %%timeit for multiple lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "old_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 423 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "new_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 ms ± 20.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "old_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.1 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "new_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = cProfile.Profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.runcall(new_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler2 = cProfile.Profile()\n",
    "profiler2.runcall(new_h)\n",
    "profiler2.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your result, then view them later with pstats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('old_h()', 'old_h.stats')\n",
    "cProfile.run('new_h()', 'new_h.stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('old_s()', 'old_s.stats')\n",
    "cProfile.run('new_s()', 'new_s.stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 2018-05-18: vectorized_simsignals much improved! e.g. of 3.49 s on spin 11, 3.39s spent on intensity_and_energy (the calculation of I and E) and only 0.083s on the conversion to a spectrum!\n",
    "Right now, Hamiltonian is not the bottleneck, and is as fast as it's going to get (for now).\n",
    "In the new simsignals, the eigh is definitely the bottleneck (e.g. 2.8 out of 4.5 s) so probably can't be improved on much. However, of that ~4.5 s, ~0.86 s occurs within simsignals, so presumably in the loop. Can this be vectorized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pstats.Stats('new_s.stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.print_callees('dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier in jupyter to do this with prun.\n",
    "-l 12 limits to 12 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 12\n",
    "new_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 12\n",
    "newer_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_new_s = %prun -r new_s()  # -r returns the pstats object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_new_s.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -T stats_new_s.txt new_s()  # -T saves results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%less stats_new_s.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -D stats_new_s.stats new_s()  # saves as binary instead (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_new_s():\n",
    "    start_os_time0 = os.times()[0]\n",
    "    start_time_clock = time.clock()\n",
    "    start_default_timer = timeit.default_timer()\n",
    "    start_perf = time.perf_counter()\n",
    "    start_processtime = time.process_time()\n",
    "    new_s()\n",
    "    duration_os_time0 = os.times()[0] - start_os_time0\n",
    "    duration_time_clock = time.clock() - start_time_clock\n",
    "    duration_default_timer = timeit.default_timer() - start_default_timer\n",
    "    duration_perf = time.perf_counter() - start_perf\n",
    "    duration_processtime = time.process_time() - start_processtime\n",
    "    print('os: ', duration_os_time0)\n",
    "    print('time_clock: ', duration_time_clock)\n",
    "    print('default_timer: ', duration_default_timer)\n",
    "    print('perf: ', duration_perf)\n",
    "    print('processtime: ', duration_processtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_new_s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muller's recommendation is to use default_timer, which abstracts OS differences away. Very different behavior btwen Windows and Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.process_time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%snakeviz new_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load candidates.py\n",
    "\"\"\"Collection of the current best candidates for nmrtools functions,\n",
    "for testing speed etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from nmrtools.nmrmath import hamiltonian as current_hamiltonian\n",
    "from nmrtools.nmrmath import simsignals as current_simsignals\n",
    "\n",
    "from speedtest.compare_hamiltonians import hamiltonian_sparse as \\\n",
    "    candidate_hamiltonian\n",
    "from tests.test_simsignals import newer_simsignals as candidate_simsignals\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import numpy as np\n",
    "    from simulation_data import rioux\n",
    "    current_h = current_hamiltonian(*rioux())\n",
    "    current_spectrum = current_simsignals(current_h, 3)\n",
    "    candidate_h = candidate_hamiltonian(*rioux())\n",
    "    candidate_spectrum = candidate_simsignals(candidate_h, 3)\n",
    "\n",
    "    print(current_spectrum[:10])\n",
    "    print(candidate_spectrum[:10])\n",
    "    assert np.allclose(current_spectrum, candidate_spectrum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f candidate_simsignals candidate_simsignals(new11_h, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 2018-05-18: new vectorization reduces new_compile_spectrum (vectorization of loop) to only 3% of time! Eigh is the clear bottleneck.\n",
    "kernprof indicates that eigen is bottleneck, but the for loop is not insignificant. Perhaps this can be vectorized at some point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.test_simsignals import intensity_and_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f intensity_and_energy candidate_simsignals(new11_h, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In intensity_and_energy, eigh is 90% of the time, and the matrix multiplication 9.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nmr)",
   "language": "python",
   "name": "nmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
